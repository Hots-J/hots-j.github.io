<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.1.1"><link rel="apple-touch-icon" sizes="180x180" href="/images/avatar.ico"><link rel="icon" type="image/png" sizes="32x32" href="/images/avatar.ico"><link rel="icon" type="image/png" sizes="16x16" href="/images/avatar.ico"><link rel="mask-icon" href="/images/avatar.ico" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.14.0/css/all.min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/pace-js@1.0.2/themes/blue/pace-theme-minimal.css"><script src="//cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><script class="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"cjerome.top",root:"/",scheme:"Gemini",version:"8.0.0",exturl:!1,sidebar:{position:"left",display:"post",padding:18,offset:12},copycode:!0,bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!1,pangu:!1,comments:{style:"tabs",active:null,storage:!0,lazyload:!1,nav:null},motion:{enable:!1,async:!1,transition:{post_block:"fadeIn",post_header:"fadeInDown",post_body:"fadeInDown",coll_header:"fadeInLeft",sidebar:"fadeInUp"}},prism:!1,i18n:{placeholder:"搜索...",empty:"没有找到任何搜索结果：${query}",hits_time:"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）",hits:"找到 ${hits} 个搜索结果"},path:"search.xml",localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1}}</script><meta name="description" content="1. 逻辑回归的应用 生活中的很多分类问题  贷款违约情况（会违约&#x2F;不会违约） 广告点击问题（会点击&#x2F;不会点击） 商品推荐（会购买&#x2F;不会购买） 情感分析（正面&#x2F;负面） 疾病诊断（阳性&#x2F;阴性）  等等....."><meta property="og:type" content="article"><meta property="og:title" content="逻辑回归"><meta property="og:url" content="http://cjerome.top/posts/f9b01ad8.html"><meta property="og:site_name" content="Jerome&#39;s Blog"><meta property="og:description" content="1. 逻辑回归的应用 生活中的很多分类问题  贷款违约情况（会违约&#x2F;不会违约） 广告点击问题（会点击&#x2F;不会点击） 商品推荐（会购买&#x2F;不会购买） 情感分析（正面&#x2F;负面） 疾病诊断（阳性&#x2F;阴性）  等等....."><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://i.loli.net/2020/01/10/F8azDLyptJNPiHh.png"><meta property="og:image" content="https://upload-images.jianshu.io/upload_images/7691426-17d142c9dab67649.png"><meta property="og:image" content="https://i.loli.net/2020/01/10/4pocyFSPRbMlBVN.png"><meta property="og:image" content="https://i.loli.net/2020/01/10/ZcDiI8KamQG3S2P.png"><meta property="article:published_time" content="2020-02-10T07:07:50.000Z"><meta property="article:modified_time" content="2020-09-14T11:37:36.374Z"><meta property="article:author" content="Jerome"><meta property="article:tag" content="逻辑回归"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://i.loli.net/2020/01/10/F8azDLyptJNPiHh.png"><link rel="canonical" href="http://cjerome.top/posts/f9b01ad8.html"><script class="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><title>逻辑回归 | Jerome's Blog</title><noscript><style>body{margin-top:2rem}.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header,.use-motion .sidebar{visibility:visible}.use-motion .footer,.use-motion .header,.use-motion .site-brand-container .toggle{opacity:initial}.use-motion .custom-logo-image,.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line{transform:scaleX(1)}.search-pop-overlay,.sidebar-nav{display:none}.sidebar-panel{display:block}</style></noscript></head><body itemscope itemtype="http://schema.org/WebPage"><div class="headband"></div><main class="main"><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line"></span> <span class="toggle-line"></span> <span class="toggle-line"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><i class="logo-line"></i><h1 class="site-title">Jerome's Blog</h1><i class="logo-line"></i></a><p class="site-subtitle" itemprop="description">哟，又在写bug呢？</p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" maxlength="80" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div class="search-result-container no-result"><div class="search-result-icon"><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></div><div class="toggle sidebar-toggle"><span class="toggle-line"></span> <span class="toggle-line"></span> <span class="toggle-line"></span></div><aside class="sidebar"><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class="sidebar-nav"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><section class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E5%BA%94%E7%94%A8"><span class="nav-text">1. 逻辑回归的应用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E5%8E%9F%E7%90%86"><span class="nav-text">2. 逻辑回归的原理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%80%BB%E8%BE%91%E5%87%BD%E6%95%B0"><span class="nav-text">2.1逻辑函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B0"><span class="nav-text">2.2 目标函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9C%80%E5%A4%A7%E5%8C%96%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B0"><span class="nav-text">2.3 最大化目标函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95"><span class="nav-text">2.4 优化算法</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95"><span class="nav-text">3. 梯度下降法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E7%9A%84%E6%B5%81%E7%A8%8B"><span class="nav-text">3.1 梯度下降法的流程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%AD%E4%BB%A3%E7%9A%84%E7%BB%88%E6%AD%A2%E6%9D%A1%E4%BB%B6"><span class="nav-text">3.2 迭代的终止条件</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%A2%98%E5%A4%96%E8%AF%9D"><span class="nav-text">4.题外话</span></a></li></ol></div></section><section class="site-overview-wrap sidebar-panel"><div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="Jerome" src="/images/avatar.jpg"><p class="site-author-name" itemprop="name">Jerome</p><div class="site-description" itemprop="description"></div></div><div class="site-state-wrap animated"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">37</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">8</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">25</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author animated"><span class="links-of-author-item"><a href="https://github.com/hots-j" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;hots-j" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class="links-of-author-item"><a href="https://www.zhihu.com/people/qian-qian-yang-guang-j/activities" title="知乎 → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;qian-qian-yang-guang-j&#x2F;activities" rel="noopener" target="_blank"><i class="fa fa-paw fa-fw"></i>知乎</a></span></div><div class="cc-license animated" itemprop="license"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a></div></section><div class="back-to-top animated"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div></aside><div class="sidebar-dimmer"></div></header><a href="https://github.com/hots-j" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><noscript><div class="noscript-warning">Theme NexT works best with JavaScript enabled</div></noscript><div class="main-inner post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="http://cjerome.top/posts/f9b01ad8.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="Jerome"><meta itemprop="description" content=""></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Jerome's Blog"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">逻辑回归</h1><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-02-10 15:07:50" itemprop="dateCreated datePublished" datetime="2020-02-10T15:07:50+08:00">2020-02-10</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a></span></span></div><div class="post-meta"><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>3.2k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>3 分钟</span></span></div></div></header><div class="post-body" itemprop="articleBody"><h3 id="逻辑回归的应用">1. 逻辑回归的应用</h3><p>生活中的很多分类问题</p><ul><li>贷款违约情况（会违约/不会违约）</li><li>广告点击问题（会点击/不会点击）</li><li>商品推荐（会购买/不会购买）</li><li>情感分析（正面/负面）</li><li>疾病诊断（阳性/阴性）</li></ul><p>等等.....</p><a id="more"></a><p>对于这些分类问题，我们可以采用逻辑回归的模型来进行比较好的分类。那么原理是什么呢？</p><h3 id="逻辑回归的原理">2. 逻辑回归的原理</h3><p>下面给出一个具体的例子：</p><p><img src="https://i.loli.net/2020/01/10/F8azDLyptJNPiHh.png"></p><p>对于这个分类任务，我通过学习已知的年龄、工资、学历情况和对应的是否逾期情况，来判断当年龄为27，工资为7000，学历为本科时，他逾期的概率是多少。本质上就是计算一个条件概率。而对于已知数据的学习，就是想使得对应的条件概率<code>P(Y|X)</code>越大越好。</p><p>重点是如何定义这个条件概率，如果直接用线性回归表示 <span class="math display">\[ P(Y|X;\omega)=\omega^Tx+b \]</span></p><h4 id="逻辑函数">2.1逻辑函数</h4><p>那么计算出来的是一个实值，还是无法直接通过实值进行分类。因此考虑引入逻辑函数 <span class="math display">\[ y =\sigma(x)=\frac{1}{1+e^{-x}} \]</span> 逻辑函数的图像如下</p><p><img src="https://upload-images.jianshu.io/upload_images/7691426-17d142c9dab67649.png"></p><p>此时将计算出来的值 <span class="math inline">\(z=\omega^Tx+b\)</span> 带入逻辑函数中就可以得到 <span class="math display">\[ y= \begin{cases} 0&amp; \text{z&lt;0}\\ 0.5&amp; \text{z=0}\\ 1&amp; \text{z&gt;0} \end{cases} \]</span> 即z大于0就判为正例，小于0就判为反例，为临界值0则可以任意判断。</p><h4 id="目标函数">2.2 目标函数</h4><p>因此新的条件概率就定义为 <span class="math display">\[ P(Y|X;\omega)=\sigma(\omega^Tx+b)=\frac{1}{1+e^{-(\omega^Tx+b)}} \]</span> 其中 <span class="math inline">\(\omega^T = (\omega_1, \omega_1,...,\omega_n)\)</span> ，n=特征数量。</p><p>对于上面那个具体的例子，可以列出 <span class="math display">\[ P(Y=Yes|X=(20,4000,本科))=\frac{1}{1+e^{-[{\begin{pmatrix} \omega_1 \omega_2 \omega_3\\ \end{pmatrix}}{\begin{pmatrix}20\\4000\\本科\\ \end{pmatrix}}+b]}} \\\ldots \]</span> 通过已知数据计算出，令所有似然函数都最大的参数<span class="math inline">\(\omega^T\)</span>和<span class="math inline">\(b\)</span>，最后代入要预测的特征x，就能得到最终的分类y。</p><p>对于二分类的问题： <span class="math display">\[ P(Y=1|X;\omega)=\sigma(\omega^Tx+b)=\frac{1}{1+e^{-(\omega^Tx+b)}}\\ P(Y=0|X;\omega)=1-P(Y=1|X;\omega)=\frac{e^{-(\omega^Tx+b)}}{1+e^{-(\omega^Tx+b)}} \]</span> 两个式子可以合并成 <span class="math display">\[ P(Y|X;\omega)=P(Y=1|X;\omega)^y[1-P(Y=1|X;\omega)]^{1-y} \]</span> 那么接下来的问题就是，该如何计算出参数 <span class="math inline">\(\omega^T\)</span>和<span class="math inline">\(b\)</span> 呢？</p><h4 id="最大化目标函数">2.3 最大化目标函数</h4><p>我们要最大化目标函数，从而求出 <span class="math inline">\(\omega^T\)</span>和<span class="math inline">\(b\)</span> ，即 <span class="math display">\[ \hat{\omega},\hat{b}=argmax_{\omega,b}\prod_{i=1}^n p(y_i|x_i,w,b) \]</span> 两边取对数 <span class="math display">\[ =argmax_{\omega,b}log(\prod_{i=1}^n p(y_i|x_i,w,b))\\ =argmax_{\omega,b}\sum_{i=1}^nlog( p(y_i|x_i,w,b)) \]</span> 取负号，即最小化目标函数 <span class="math display">\[ =argmin_{\omega,b}-\sum_{i=1}^nlog( p(y_i|x_i,w,b))\\ =argmin_{\omega,b}-\sum_{i=1}^nlog[p(y_i=1|x_i;\omega,b)^{y_i}[1-p(y_i=1|x_i;\omega,b]^{1-{y_i}}]\\ =argmin_{\omega,b}-\sum_{i=1}^n[y_ilog(p(y_i=1|x_i;\omega,b))+(1-y_i)log(1-p(y_i=1|x_i;\omega,b))] \]</span> 接下来就是通过优化算法把目标函数的最优解计算出来。</p><p>如何寻找一个函数最大化或者最小化的最优解？</p><h4 id="优化算法">2.4 优化算法</h4><p>对于凸函数来说，对函数求出的最优解一般就算全局最优解。</p><p>对于非凸函数来说，求出的最优解一般是局部最优解，不一定是全局最优解。</p><p>该如何选择优化算法呢？</p><p>对于简单的函数，直接求导，令导数为0，就能把参数解出来。但是对于复杂的函数，无法直接求出参数，因此我们要采用数值优化的思路，通过循环迭代的方式找到最优的参数。</p><p>最常用的优化算法就是梯度下降法（ Gradient Descent ）</p><h3 id="梯度下降法">3. 梯度下降法</h3><p>求使得<span class="math inline">\(f(w)\)</span>值最小的参数<span class="math inline">\(w\)</span></p><p><img src="https://i.loli.net/2020/01/10/4pocyFSPRbMlBVN.png"></p><p><span class="math inline">\(\eta\)</span>为学习率，也就是梯度下降的步长。</p><p>对于上面具体的例子，我们知道 <span class="math display">\[ P(y=1|x;\omega)=\sigma(\omega^Tx+b)=\frac{1}{1+e^{-(\omega^Tx+b)}} \]</span> 以及目标函数 <span class="math display">\[ =argmin_{\omega,b}-\sum_{i=1}^n[y_ilog(p(y_i=1|x_i;\omega,b))+(1-y_i)log(1-p(y_i=1|x_i;\omega,b))]\\ =argmin_{\omega,b}-\sum_{i=1}^n[y_ilog(\sigma(\omega^Tx_i+b))+(1-y_i)log(1-\sigma(\omega^Tx_i+b))] \]</span> 令 <span class="math display">\[ L(w,b)=-\sum_{i=1}^n[y_ilog(\sigma(\omega^Tx_i+b))+(1-y_i)log(1-\sigma(\omega^Tx_i+b))] \]</span> 又 <span class="math display">\[ \frac{\partial \sigma(x)}{\partial x}=\sigma(x)\cdot[1-\sigma(x)] \]</span> 则 <span class="math display">\[ \frac{\partial L(w,b)}{\partial w}=\sum_{i=1}^n[\sigma(\omega^Tx_i+b)-y_i]\cdot{x_i} \]</span></p><p><span class="math display">\[ \frac{\partial L(w,b)}{\partial b}=\sum_{i=1}^n[\sigma(\omega^Tx_i+b)-y_i] \]</span></p><p>观察求导后的式子，可以发现<span class="math inline">\(\sigma(\omega^Tx_i+b)\)</span>是当前的参数计算出的预测值，<span class="math inline">\(y_i\)</span>是真实值，所以就是通过当前的预测值与真实值的差来调整新的参数。</p><h4 id="梯度下降法的流程">3.1 梯度下降法的流程</h4><p>因此最终的梯度下降法的流程为</p><p><img src="https://i.loli.net/2020/01/10/ZcDiI8KamQG3S2P.png"></p><h4 id="迭代的终止条件">3.2 迭代的终止条件</h4><p>有一个问题，这个循环的终止条件是什么？</p><ol type="1"><li>计算目标函数<span class="math inline">\(L(w,b)\)</span>的值，如果变化幅度很小很小，就可以停止迭代了</li><li>计算<span class="math inline">\(|w^{t+1}-w^{t}|\)</span>，如果基本不变了，就可以停止</li><li>通过计算验证集的正确率</li><li>直接迭代1w次或者更多次，如果学习率设置合理，那么最终一定会收敛</li></ol><h3 id="题外话">4.题外话</h3><p>逻辑回归是线性分类器吗？如何判断一个分类器是不是线性分类器呢？</p><p>判断是不是线性分类器根本是判断模型的决策边界是不是线性的。</p><p>对于二分类的问题，我们知道决策边界有个性质，就是落在决策边界上的点被分成1或者0的概率是相等的。</p><p>因此可以得到决策边界的方程 <span class="math display">\[ \frac {P(Y=1|X;\omega)}{P(Y=0|X;\omega)}=1 \]</span> 化简为</p><p><span class="math display">\[ \frac{\frac{1}{1+e^{-(\omega^Tx+b)}}}{\frac{e^{-(\omega^Tx+b)}}{1+e^{-(\omega^Tx+b)}}}=1\\ e^{-(\omega^Tx+b)}=1 \]</span></p><p>即</p><p><span class="math display">\[ \omega^Tx+b=0 \]</span></p><p>因为决策边界是线性的，所以逻辑回归也是线性的分类器。</p></div><footer class="post-footer"><div><div style="text-align:center;color:#ccc;font-size:14px">-------------本文结束 <i class="fa fa-paw"></i> 感谢您的阅读-------------</div></div><div class="post-copyright"><ul><li class="post-copyright-author"><strong>本文作者： </strong>Jerome</li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="http://cjerome.top/posts/f9b01ad8.html" title="逻辑回归">http://cjerome.top/posts/f9b01ad8.html</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class="post-tags"><a href="/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/" rel="tag"><i class="fa fa-tag"></i> 逻辑回归</a></div><div class="post-nav"><div class="post-nav-item"><a href="/posts/acd40dbf.html" rel="prev" title="Hexo+Github搭建自己的博客(二)"><i class="fa fa-chevron-left"></i> Hexo+Github搭建自己的博客(二)</a></div><div class="post-nav-item"><a href="/posts/cb29d277.html" rel="next" title="PCA的数学分析">PCA的数学分析 <i class="fa fa-chevron-right"></i></a></div></div></footer></article><script>window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }</script></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2020</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">Jerome</span></div><div class="wordcount"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-chart-line"></i> </span><span>站点总字数：</span> <span title="站点总字数">88k</span></span></div></div></footer><script src="//cdn.jsdelivr.net/npm/animejs@3.2.0/lib/anime.min.js"></script><script src="/js/utils.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><script>if (typeof MathJax === 'undefined') {
    window.MathJax = {
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              const target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    const script = document.createElement('script');
    script.src = '//cdn.jsdelivr.net/npm/mathjax@3.1.0/es5/tex-mml-chtml.js';
    script.defer = true;
    document.head.appendChild(script);
  } else {
    MathJax.startup.document.state(0);
    MathJax.typesetClear();
    MathJax.texReset();
    MathJax.typeset();
  }</script></body></html>